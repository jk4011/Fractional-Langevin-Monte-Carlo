{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ3CQwRkA__B"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm.notebook as tqdm\n",
        "\n",
        "from scipy.stats import levy_stable\n",
        "from scipy.special import gamma as gamma_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNZzOb44BBwq"
      },
      "outputs": [],
      "source": [
        "class Fractional_Langevin_MonteCarlo():\n",
        "    def __init__(self, m=None):\n",
        "        self.m = m\n",
        "\n",
        "    def phi(self, U):\n",
        "        # unnormalized target density : exp(-U(X))\n",
        "        return torch.exp(-U)\n",
        "\n",
        "    def drift_hat(self, x, alpha, U):\n",
        "        # simplified multidimensional drift\n",
        "        # approximate fractional derivative by using only the first term of centered difference operator\n",
        "\n",
        "        x.requires_grad_()\n",
        "        u = U(x)\n",
        "        grad = torch.autograd.grad(u, x)[0]\n",
        "        \n",
        "        def c_alpha(alpha):\n",
        "            return gamma_func(alpha-1) / gamma_func(alpha/2)**2\n",
        "\n",
        "        return -c_alpha(alpha) * grad\n",
        "    \n",
        "    def FLA(self, U, alpha, N, a_eta, b_eta, step_size, dim):\n",
        "        # Fractional Langevin Algorithm(FLA)\n",
        "        # when alpha = 2, FLA is same as ULA\n",
        "        burn_in = 5000\n",
        "        x_0 = torch.randn(1, dim).double()\n",
        "\n",
        "        Levy_motions = levy_stable.rvs(alpha, 0, size=dim * (N + burn_in))\n",
        "        Levy_motions = torch.from_numpy(Levy_motions.reshape((Levy_motions.shape[0] // dim, dim)))\n",
        "        #Brownian_motions = torch.randn(N + burn_in, dim)\n",
        "\n",
        "        x_i = x_0\n",
        "        samples = []\n",
        "        num_nan = 0\n",
        "\n",
        "        for i in tqdm.tqdm(range(N + burn_in)):\n",
        "            #step_size = (a_eta/(i+1))**b_eta\n",
        "            step_size = step_size\n",
        "            b = self.drift_hat(x_i, alpha, U)\n",
        "            x_i = x_i.detach() + step_size * b + step_size ** (1./alpha) * Levy_motions[i]\n",
        "            #x_i = x_i.detach() + step_size * b + step_size ** (1./alpha) * Brownian_motions[i]                        \n",
        "\n",
        "            if True in np.isnan(x_i):\n",
        "                num_nan += 1\n",
        "            else:\n",
        "                if dim > 1:\n",
        "                    samples.append(x_i.detach().numpy())\n",
        "                else:\n",
        "                    samples.append(x_i.detach().numpy().squeeze())\n",
        "\n",
        "        print(f\"{N} samples are generated, and then {num_nan} samples are excluded due to NAN\")\n",
        "        if dim > 1:\n",
        "            return np.concatenate(samples, 0)[burn_in:]\n",
        "        else:\n",
        "            return samples[burn_in:]\n",
        "\n",
        "FLMC = Fractional_Langevin_MonteCarlo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1VbPQ4G-W-H"
      },
      "source": [
        "# Experiment #1\n",
        "1 dimensional space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCe8AQUJTya8"
      },
      "outputs": [],
      "source": [
        "FLMC = Fractional_Langevin_MonteCarlo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5alaj3hNk5l"
      },
      "outputs": [],
      "source": [
        "# Section 4. Experiment with double-well potential\n",
        "def double_well_potential_np(x):\n",
        "    U = (x+5)*(x+1) * (x-1.02) * (x-5) / 10 + 0.5\n",
        "    return np.exp(-U)\n",
        "\n",
        "def double_well_potential(x):\n",
        "    U = (x+5)*(x+1) * (x-1.02) * (x-5) / 10 + 0.5\n",
        "    return U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo-bX0a5PTOb"
      },
      "outputs": [],
      "source": [
        "# Visualize Figure 2 (top) in paper\n",
        "x = np.linspace(-6, 6, 1000)\n",
        "y = double_well_potential_np(x)\n",
        "\n",
        "plt.figure(figsize = (10,2))\n",
        "plt.plot(x, y)\n",
        "plt.title('Figure 2 (Top)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VrSxdSuPOP8"
      },
      "outputs": [],
      "source": [
        "# Visualize Figure 2 (middle) in paper\n",
        "# empirical distribution obtained via ULA (corresponds to FLA with alpha = 2)\n",
        "samples = FLMC.FLA(U=double_well_potential, alpha=2, N=100000, a_eta=1e-7, b_eta=0.6, step_size=0.001, dim=1)\n",
        "\n",
        "plt.figure(figsize = (10,2))\n",
        "plt.hist(samples, bins=200, density=True)\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.title('Figure 2 (Middle)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Figure 2 (bottom) in paper\n",
        "# empirical distribution obtained via FLA (alpha = 1.7)\n",
        "samples = FLMC.FLA(U=double_well_potential, alpha=1.75, N=100000, a_eta=1e-7, b_eta=0.6, step_size=0.001, dim=1)\n",
        "\n",
        "plt.figure(figsize = (10,2))\n",
        "plt.hist(samples, bins=200, density=True)\n",
        "plt.title('Figure 2 (Middle)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQMC_wJf-gtP"
      },
      "source": [
        "# Experiment #2\n",
        "2 dimensional space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrwOeYEauWgJ"
      },
      "outputs": [],
      "source": [
        "def potential1_np(z):\n",
        "    z1, z2 = z[:, 0], z[:, 1]\n",
        "    norm = np.sqrt(z1 ** 2 + z2 ** 2)\n",
        "    exp1 = np.exp(-0.5 * ((z1 - 2) / 0.6) ** 2)\n",
        "    exp2 = np.exp(-0.5 * ((z1 + 2) / 0.6) ** 2)\n",
        "    u = 0.5 * ((norm - 2) / 0.4) ** 2 - np.log(exp1 + exp2)\n",
        "    return np.exp(-u)\n",
        "\n",
        "def potential1(z):\n",
        "    z = z.view(-1, 2).double()\n",
        "    z1, z2 = z[:, 0], z[:, 1]\n",
        "    norm = torch.norm(z, p=2, dim=1)\n",
        "    exp1 = torch.exp(-0.5 * ((z1 - 2) / 0.6) ** 2)\n",
        "    exp2 = torch.exp(-0.5 * ((z1 + 2) / 0.6) ** 2)\n",
        "    u = 0.5 * ((norm - 2) / 0.4) ** 2 - torch.log(exp1 + exp2)\n",
        "    return u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIcK0TEPuVZj"
      },
      "outputs": [],
      "source": [
        "r = np.linspace(-5, 5, 1000)\n",
        "x, y = np.meshgrid(r, r)\n",
        "z = np.vstack([x.flatten(), y.flatten()]).T\n",
        "\n",
        "q0 = potential1_np(z)\n",
        "plt.pcolormesh(x, y, q0.reshape(x.shape),\n",
        "                           cmap='viridis')\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])\n",
        "plt.title('Density #1')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7z5bNhUv0C-"
      },
      "outputs": [],
      "source": [
        "samples1 = FLMC.FLA(potential1, alpha=1.7, N =100000, a_eta=1e-7, b_eta=0.6, step_size=0.00001, dim=2)\n",
        "\n",
        "plt.hist2d(samples1[:,0], samples1[:,1], cmap='viridis', rasterized=False, bins=200, density=True)\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlim([-3.5, 3.5])\n",
        "plt.ylim([-3.5, 3.5])\n",
        "plt.title('Empirical Density #1')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAzjOo6hz4w0"
      },
      "outputs": [],
      "source": [
        "def potential2_np(z):\n",
        "    x, y = z[:, 0], z[:, 1]\n",
        "    u = 0.8 * x ** 2 + (y - ((x**2)**(1/3)))**2\n",
        "    u = u / 2**2\n",
        "    return np.exp(-u)\n",
        "\n",
        "\n",
        "def potential2(z):\n",
        "    z = z.view(-1, 2).double()\n",
        "    x, y = z[:, 0], z[:, 1]\n",
        "    u = 0.8 * x ** 2 + (y - ((x**2)**(1/3)))**2\n",
        "    u = u / 2**2\n",
        "    return u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4MdAttquV5e"
      },
      "outputs": [],
      "source": [
        "r = np.linspace(-5, 5, 1000)\n",
        "x, y = np.meshgrid(r, r)\n",
        "z = np.vstack([x.flatten(), y.flatten()]).T\n",
        "\n",
        "q0 = potential2_np(z)\n",
        "plt.pcolormesh(x, y, q0.reshape(x.shape),\n",
        "                           cmap='viridis')\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlim([-3.5, 3.5])\n",
        "plt.ylim([-3.5, 3.5])\n",
        "plt.title('Density #2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA84yNxpz08I"
      },
      "outputs": [],
      "source": [
        "samples2 = FLMC.FLA(potential2, alpha=1.7, N =100000, a_eta=1e-7, b_eta=0.6, step_size=0.001, dim=2)\n",
        "\n",
        "plt.hist2d(samples2[:,0], samples2[:,1], cmap='viridis', rasterized=False, bins=200, density=True)\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlim([-3.5, 3.5])\n",
        "plt.ylim([-3.5, 3.5])\n",
        "plt.title('Empirical Density #2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment #3\n",
        "2 dimensional space with more complicated multi-modal density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLB8fdssB32v"
      },
      "outputs": [],
      "source": [
        "def multivariate_normal_np(x, mean, cov, d):\n",
        "    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
        "    # 2-dimension\n",
        "    B = x.shape[0]\n",
        "    mean = np.array([[mean[0], mean[1]]])\n",
        "    \n",
        "    x_m = x - mean\n",
        "    x_m = np.array(x_m).reshape(B, d, 1)\n",
        "\n",
        "    first_term = 1. / (np.sqrt((2 * np.pi)**d * np.linalg.det(cov)))\n",
        "    temp = np.linalg.solve(cov, x_m)\n",
        "    temp = temp.reshape(B,1,d)\n",
        "    u = np.matmul(temp,x_m) / 2\n",
        "    second_term = np.exp(-u)\n",
        "\n",
        "    out = (first_term * second_term).squeeze()\n",
        "\n",
        "    return out\n",
        "\n",
        "    \n",
        "def gaussian_mixture_np(z):\n",
        "    # d : dimension of x - Multivariate Gaussian\n",
        "    # m : number of mixtures - Gaussian Mixture\n",
        "    # means : m x d\n",
        "    d = 2\n",
        "    m = 6\n",
        "    means = np.array([[-2,0.5],[-1.5,-1],[0.5,-2],[2,-0.5],[1.5,1],[-1,1.5]])\n",
        "    covs = np.array([[[0.5,0],[0,1]],[[1,-0.5],[-0.5,1]],[[1,0.5],[0.5,1]],[[0.5,0],[0,1]],[[1,-0.5],[-0.5,1]],[[1,0],[0,0.5]]])\n",
        "\n",
        "    u = np.zeros(z.shape[0], dtype='float64')\n",
        "\n",
        "    for i in range(m):\n",
        "        u += multivariate_normal_np(z, means[i], covs[i], d)\n",
        "\n",
        "    return u\n",
        "\n",
        "def multivariate_normal(x, mean, cov, d):\n",
        "    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
        "    # 2-dimension    \n",
        "    x_m = (x - mean).T\n",
        "\n",
        "    first_term = 1. / (torch.sqrt((2 * torch.pi)**d * torch.linalg.det(cov)))\n",
        "    temp = torch.linalg.solve(cov, x_m)\n",
        "    u = torch.matmul(temp.T, x_m) / 2\n",
        "    u *= first_term\n",
        "\n",
        "    return u.squeeze(-1)\n",
        "\n",
        "    \n",
        "def gaussian_mixture(z):\n",
        "    # d : dimension of x - Multivariate Gaussian\n",
        "    # m : number of mixtures - Gaussian Mixture\n",
        "    # means : m x d\n",
        "    d = 2\n",
        "    m = 6\n",
        "    means = torch.tensor([[-2,0.5],[-1.5,-1],[0.5,-2],[2,-0.5],[1.5,1],[-1,1.5]], dtype=torch.double, requires_grad=True)\n",
        "    covs = torch.tensor([[[0.5,0],[0,1]],[[1,-0.5],[-0.5,1]],[[1,0.5],[0.5,1]],[[0.5,0],[0,1]],[[1,-0.5],[-0.5,1]],[[1,0],[0,0.5]]], dtype=torch.double, requires_grad=True)\n",
        "\n",
        "    z = z.view(-1, 2).double()\n",
        "\n",
        "    u = 0\n",
        "    for i in range(m):\n",
        "        u += multivariate_normal(z, means[i], covs[i], d)\n",
        "\n",
        "    return u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "r = np.linspace(-3, 3, 1000)\n",
        "x, y = np.meshgrid(r, r)\n",
        "z = np.vstack([x.flatten(), y.flatten()]).T\n",
        "\n",
        "q0 = gaussian_mixture_np(z)\n",
        "q0 = np.array(q0)\n",
        "plt.pcolormesh(x, y, q0.reshape(x.shape),\n",
        "                           cmap='viridis')\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlim([-3.5, 3.5])\n",
        "plt.ylim([-3.5, 3.5])\n",
        "plt.title('Gaussian mixture')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "samples3 = FLMC.FLA(gaussian_mixture, alpha=2.0, N =100000, a_eta=1e-7, b_eta=0.6, step_size=0.1, dim=2)\n",
        "\n",
        "plt.hist2d(samples3[:,0], samples3[:,1], cmap='viridis', rasterized=False, bins=200, density=True)\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlim([-3.5, 3.5])\n",
        "plt.ylim([-3.5, 3.5])\n",
        "plt.title('Empirical Density #3')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multivariate_normal_np(x, mean, cov, d):\n",
        "    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
        "    # 2-dimension\n",
        "    B = x.shape[0]\n",
        "    mean = np.array([[mean[0], mean[1]]])\n",
        "    \n",
        "    x_m = x - mean\n",
        "    x_m = np.array(x_m).reshape(B, d, 1)\n",
        "\n",
        "    first_term = 1. / (np.sqrt((2 * np.pi)**d * np.linalg.det(cov)))\n",
        "    temp = np.linalg.solve(cov, x_m)\n",
        "    temp = temp.reshape(B,1,d)\n",
        "    u = np.matmul(temp,x_m) / 2\n",
        "    second_term = np.exp(-u)\n",
        "\n",
        "    out = (first_term * second_term).squeeze()\n",
        "\n",
        "    return out\n",
        "\n",
        "    \n",
        "def gaussian_mixture_np(z):\n",
        "    # d : dimension of x - Multivariate Gaussian\n",
        "    # m : number of mixtures - Gaussian Mixture\n",
        "    # means : m x d\n",
        "    d = 2\n",
        "    m = 2\n",
        "    means = np.array([[-2,0.5],[0.5,-2],[1.5,1]])\n",
        "    covs = np.array([[[0.5,0],[0,1]],[[0.5,0],[0,1]],[[1,0.5],[0.5,1]],[[1,-0.5],[-0.5,1]]])\n",
        "\n",
        "    u = np.zeros(z.shape[0], dtype='float64')\n",
        "\n",
        "    for i in range(m):\n",
        "        u += multivariate_normal_np(z, means[i], covs[i], d)\n",
        "\n",
        "    return u\n",
        "\n",
        "def multivariate_normal(x, mean, cov, d):\n",
        "    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
        "    # 2-dimension    \n",
        "    x_m = (x - mean).T\n",
        "\n",
        "    first_term = 1. / (torch.sqrt((2 * torch.pi)**d * torch.linalg.det(cov)))\n",
        "    temp = torch.linalg.solve(cov, x_m)\n",
        "    u = torch.matmul(temp.T, x_m) / 2\n",
        "    u *= first_term\n",
        "\n",
        "    return u.squeeze(-1)\n",
        "\n",
        "    \n",
        "def gaussian_mixture(z):\n",
        "    # d : dimension of x - Multivariate Gaussian\n",
        "    # m : number of mixtures - Gaussian Mixture\n",
        "    # means : m x d\n",
        "    d = 2\n",
        "    m = 2\n",
        "    means = torch.tensor([[-2,0.5],[0.5,-2],[1.5,1]], dtype=torch.double, requires_grad=True)\n",
        "    covs = torch.tensor([[[0.5,0],[0,1]],[[0.5,0],[0,1]],[[1,0.5],[0.5,1]],[[1,-0.5],[-0.5,1]]], dtype=torch.double, requires_grad=True)\n",
        "\n",
        "    z = z.view(-1, 2).double()\n",
        "\n",
        "    u = 0\n",
        "    for i in range(m):\n",
        "        u += multivariate_normal(z, means[i], covs[i], d)\n",
        "\n",
        "    return u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r = np.linspace(-3, 3, 1000)\n",
        "x, y = np.meshgrid(r, r)\n",
        "z = np.vstack([x.flatten(), y.flatten()]).T\n",
        "\n",
        "q0 = gaussian_mixture_np(z)\n",
        "q0 = np.array(q0)\n",
        "plt.pcolormesh(x, y, q0.reshape(x.shape),\n",
        "                           cmap='viridis')\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlim([-3.5, 3.5])\n",
        "plt.ylim([-3.5, 3.5])\n",
        "plt.title('Gaussian mixture')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "samples4 = FLMC.FLA(gaussian_mixture, alpha=1.75, N =200000, a_eta=1e-7, b_eta=0.6, step_size=0.001, dim=2)\n",
        "\n",
        "plt.hist2d(samples4[:,0], samples4[:,1], cmap='viridis', rasterized=False, bins=200, density=True)\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlim([-3.5, 3.5])\n",
        "plt.ylim([-3.5, 3.5])\n",
        "plt.title('Empirical Density #4')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FLMC.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
